# POC Evaluation Scorecard

**Evaluator:** _________________
**Date Range:** _________________
**Azure Subscription:** _________________

---

## Phase 1: Greenfield Generation

### Task 1.1: Storage Account Module

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 1.2: Hub Virtual Network

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 1.3: ALZ Management Groups

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

## Phase 2: Existing Code Understanding

### Task 2.1: Explain Peering

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 2.2: Add New Spoke

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 2.3: Refactor Modules

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

## Phase 3: Debugging

### Task 3.1: RBAC Failure

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 3.2: DNS Resolution

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 3.3: Circular Dependency

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

## Phase 4: End-to-End Workflow

### Task 4.1: Deploy and Validate

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Agentic Behavior Notes:**
- Did Claude Code run commands autonomously? [ ] Yes [ ] No
- Did Copilot CLI run commands autonomously? [ ] Yes [ ] No
- Self-correction on errors? Claude: [ ] Yes [ ] No | Copilot: [ ] Yes [ ] No

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

### Task 4.2: CI/CD Pipeline

| Criterion | Claude Code | Copilot CLI |
|-----------|-------------|-------------|
| Accuracy (25%) | /5 | /5 |
| Completeness (20%) | /5 | /5 |
| Speed (15%) | /5 | /5 |
| Iteration Efficiency (15%) | /5 | /5 |
| Context Understanding (15%) | /5 | /5 |
| Explanation Quality (10%) | /5 | /5 |
| **Weighted Total** | | |

**Time:** Claude ___ min | Copilot ___ min
**Iterations:** Claude ___ | Copilot ___

**Claude Code Notes:**
-

**Copilot CLI Notes:**
-

**Winner:** [ ] Claude Code  [ ] Copilot CLI  [ ] Tie

---

## Summary

### Scores by Phase

| Phase | Claude Code Avg | Copilot CLI Avg | Winner |
|-------|-----------------|-----------------|--------|
| Phase 1: Greenfield | | | |
| Phase 2: Existing Code | | | |
| Phase 3: Debugging | | | |
| Phase 4: Workflow | | | |
| **Overall** | | | |

### Scores by Criterion (All Tasks)

| Criterion | Claude Code Avg | Copilot CLI Avg |
|-----------|-----------------|-----------------|
| Accuracy | | |
| Completeness | | |
| Speed | | |
| Iteration Efficiency | | |
| Context Understanding | | |
| Explanation Quality | | |

### Key Observations

**Claude Code Strengths:**
1.
2.
3.

**Claude Code Weaknesses:**
1.
2.
3.

**Copilot CLI Strengths:**
1.
2.
3.

**Copilot CLI Weaknesses:**
1.
2.
3.

### Recommendation

_Based on this evaluation, the recommended tool for Azure Landing Zone IaC development is:_

[ ] **Claude Code** - Best for: _______________

[ ] **Copilot CLI** - Best for: _______________

[ ] **Both** - Use Claude Code for ___________, Copilot CLI for ___________

### Additional Notes

